{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochSaver(gensim.models.callbacks.CallbackAny2Vec):\n",
    "    '''用于保存模型, 打印损失函数等等'''\n",
    "    def __init__(self, savedir, save_name=\"word2vector.model\"):\n",
    "        os.makedirs(savedir, exist_ok=True)\n",
    "        self.save_path = os.path.join(savedir, save_name)\n",
    "        self.epoch = 0\n",
    "        self.pre_loss = 0\n",
    "        self.best_loss = 999999999.9\n",
    "        self.since = time.time()\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        self.epoch += 1\n",
    "        cum_loss = model.get_latest_training_loss() # 返回的是从第一个epoch累计的\n",
    "        epoch_loss = cum_loss - self.pre_loss\n",
    "        time_taken = time.time() - self.since\n",
    "        print(\"Epoch %d, loss: %.2f, time: %dmin %ds\" % \n",
    "                    (self.epoch, epoch_loss, time_taken//60, time_taken%60))\n",
    "        if self.best_loss > epoch_loss:\n",
    "            self.best_loss = epoch_loss\n",
    "            print(\"Better model. Best loss: %.2f\" % self.best_loss)\n",
    "            model.save(self.save_path)\n",
    "            print(\"Model %s save done!\" % self.save_path)\n",
    "\n",
    "        self.pre_loss = cum_loss\n",
    "        self.since = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train =pd.read_csv('/home/kesci/input/bytedance/train_final.csv',names=['qId','q','aId','a','target'],nrows=50000000)\n",
    "df_test=pd.read_csv('/home/kesci/input/bytedance/bytedance_contest.final_2.csv',names=['qId','q','aId','a'])\n",
    "df_test['a']=df_test['a'].apply(lambda x:x[:-1])\n",
    "w2vmodel=Word2Vec.load('/home/kesci/work/w2vfinal_all.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_fun(df):\n",
    "    print('start')\n",
    "    result=[]\n",
    "    def sent2vec(s):\n",
    "        words = str(s).split()\n",
    "        M = []\n",
    "        for w in words:\n",
    "            try:\n",
    "                M.append(w2vmodel[w])\n",
    "            except:\n",
    "                continue\n",
    "        M = np.array(M)\n",
    "        v = M.sum(axis=0)\n",
    "        return v / np.sqrt((v ** 2).sum())\n",
    "    def w2v_distances(q,a):\n",
    "        x = np.nan_to_num(sent2vec(q))\n",
    "        y = np.nan_to_num(sent2vec(a))\n",
    "        result.append([cosine(x, y),cityblock(x, y),canberra(x, y),euclidean(x, y),minkowski(x, y, 3),braycurtis(x, y)])\n",
    "    df.apply(lambda row: w2v_distances(row['q'], row['a']), axis=1)\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df_train[['q','a']].iloc[0:10000000,]\n",
    "df2=df_train[['q','a']].iloc[10000000:20000000,]\n",
    "df3=df_train[['q','a']].iloc[20000000:30000000,]\n",
    "df4=df_train[['q','a']].iloc[30000000:40000000,]\n",
    "df5=df_train[['q','a']].iloc[40000000:50000000,]\n",
    "\n",
    "df6=df_test[['q','a']].iloc[0:10000000,]\n",
    "df7=df_test[['q','a']].iloc[10000000:20000000,]\n",
    "df8=df_test[['q','a']].iloc[20000000:30000000,]\n",
    "df9=df_test[['q','a']].iloc[30000000:40000000,]\n",
    "df10=df_test[['q','a']].iloc[40000000:50000000,]\n",
    "df11=df_test[['q','a']].iloc[50000000:60000000,]\n",
    "df12=df_test[['q','a']].iloc[60000000:70000000,]\n",
    "df13=df_test[['q','a']].iloc[70000000:80000000,]\n",
    "df14=df_test[['q','a']].iloc[80000000:90000000,]\n",
    "df15=df_test[['q','a']].iloc[90000000:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train,df_test\n",
    "import gc\n",
    "gc.collect()\n",
    "from multiprocessing import cpu_count\n",
    "from multiprocessing import Pool\n",
    "print(cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p= Pool(15)\n",
    "df1=p.apply_async(q_fun, args=(df1,))\n",
    "df2=p.apply_async(q_fun, args=(df2,))\n",
    "df3=p.apply_async(q_fun, args=(df3,))\n",
    "df4=p.apply_async(q_fun, args=(df4,))\n",
    "df5=p.apply_async(q_fun, args=(df5,))\n",
    "df6=p.apply_async(q_fun, args=(df6,))\n",
    "df7=p.apply_async(q_fun, args=(df7,))\n",
    "df8=p.apply_async(q_fun, args=(df8,))\n",
    "df9=p.apply_async(q_fun, args=(df9,))\n",
    "df10=p.apply_async(q_fun, args=(df10,))\n",
    "df11=p.apply_async(q_fun, args=(df11,))\n",
    "df12=p.apply_async(q_fun, args=(df12,))\n",
    "df13=p.apply_async(q_fun, args=(df13,))\n",
    "df14=p.apply_async(q_fun, args=(df14,))\n",
    "df15=p.apply_async(q_fun, args=(df15,))\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.get()\n",
    "df2=df2.get()\n",
    "df3=df3.get()\n",
    "df4=df4.get()\n",
    "df5=df5.get()\n",
    "df6=df6.get()\n",
    "df7=df7.get()\n",
    "df8=df8.get()\n",
    "df9=df9.get()\n",
    "df10=df10.get()\n",
    "df11=df11.get()\n",
    "df12=df12.get()\n",
    "df13=df13.get()\n",
    "df14=df14.get()\n",
    "df15=df15.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.concat([df1,df2,df3,df4,df5])\n",
    "test=pd.concat([df6,df7,df8,df9,df10,df11,df12,df13,df14,df15])\n",
    "train.columns=['w2vcos','w2vcity','w2vcanb','w2veuc','w2vmin','w2vbray']\n",
    "test.columns=['w2vcos','w2vcity','w2vcanb','w2veuc','w2vmin','w2vbray']\n",
    "train.to_csv('/home/kesci/work/train_feature_w2vdis_final.csv',index=False)\n",
    "test.to_csv('/home/kesci/work/test_feature_w2vdis_final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
